{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4232c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5e6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(5, device=device)\n",
    "    x = x.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b9e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c960263",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dbd1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d204751",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,requires_grad=True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5322c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2106, -0.4876, -1.8163], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95761d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31f8a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2106, 1.5124, 0.1837], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf48d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y*y*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c951c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.7732, 4.5745, 0.0675], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da26163",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c708214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8051, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7700489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9474, 2.0165, 0.2449], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "z.backward() # does dz/dx auto\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42aabd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20.6084, 10.4014,  7.5426], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,requires_grad=True, device = device)\n",
    "y = x+2\n",
    "z = y*y*2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e44b6f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 1.0000, 0.0010], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector jacovian product...?\n",
    "v = torch.tensor([.1,1,0.001], dtype=torch.float32, device = device)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59bbb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70cac886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2840e+00, 9.1220e+00, 7.7679e-03], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192dc878",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "498a10f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0', grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, device = device)\n",
    "y = torch.tensor(2.0,device = device)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad = True, device = device)\n",
    "\n",
    "# fwd\n",
    "ycap = w*x\n",
    "loss = (ycap-y)**2\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b8ca978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# bkwd\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871e1db",
   "metadata": {},
   "source": [
    "## autoShiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b36040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design model(input,output size, fwd pass (layers))\n",
    "# construct loss and optimizer\n",
    "# training loop\n",
    "## fwd pass\n",
    "## .backward()\n",
    "## update wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4173ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "tensor([[5.6265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "0.8730513453483582 0 2.6617393493652344\n",
      "0.5076146721839905 10 0.34249240159988403\n",
      "0.4379883110523224 20 0.2665614187717438\n",
      "0.4162631332874298 30 0.24959738552570343\n",
      "0.4025537371635437 40 0.23503205180168152\n",
      "0.3904353976249695 50 0.22135096788406372\n",
      "0.3788658380508423 60 0.20846717059612274\n",
      "0.36766862869262695 70 0.19633325934410095\n",
      "0.3568071722984314 80 0.18490566313266754\n",
      "0.34626737236976624 90 0.1741432398557663\n",
      "tensor([[2.6943]], device='cuda:0')\n",
      "tensor([[7.3057]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# model\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32, device = device)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32, device = device)\n",
    "\n",
    "Xtest = torch.tensor([[5]], dtype=torch.float32, device = device)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "ipSize = n_features\n",
    "opSize = n_features\n",
    "model = nn.Linear(ipSize, opSize, device = device)\n",
    "\n",
    "\n",
    "\n",
    "# loss:\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# opt\n",
    "# opt = torch.optim.SGD([w],lr=0.01)\n",
    "opt = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "\n",
    "# How to predict?:\n",
    "print(model(Xtest))\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # smthing fwd\n",
    "    ycap = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y,ycap)\n",
    "    \n",
    "    # bkd\n",
    "    l.backward()\n",
    "    \n",
    "    # step\n",
    "    opt.step()\n",
    "    \n",
    "    # zero grad\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        w,b = model.parameters()\n",
    "        print(w[0].item(),epoch, l.item())\n",
    "\n",
    "yTest = torch.tensor([[10]], dtype=torch.float32, device = device)\n",
    "with torch.no_grad():\n",
    "    ycap = model(Xtest)\n",
    "    print(ycap)\n",
    "    acc = (yTest-ycap)/float(yTest.shape[0])\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3652f6",
   "metadata": {},
   "source": [
    "## Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c716ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdb1f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.transforms.Compose([class1(),class2(),...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0336732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "# outputs = torch.softmax(x, dim=0) but don't do this, Xent of torch will auto apply\n",
    "\n",
    "# Xent:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax + nnNLLLoss\n",
    "# y shouldn't be one hotencoded\n",
    "# \n",
    "Y = torch.tensor([[0.5,2.0,0.3]], device = device)\n",
    "#l1 =  \n",
    "\n",
    "# while flatenning you do -1, 16*5*5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
